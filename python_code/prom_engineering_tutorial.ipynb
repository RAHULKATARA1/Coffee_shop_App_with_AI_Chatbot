{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client,model_name,messages,temperature=0):\n",
    "    input_messages = []\n",
    "    for message in messages:\n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=input_messages,\n",
    "        temperature=temperature,\n",
    "        top_p=0.8,\n",
    "        max_tokens=2000,\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv('RUNPOD_TOKEN'),\n",
    "    base_url=os.getenv('RUNPOD_CHATBOT_URL')\n",
    ")\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Italy is Rome (Italian: Roma).\n"
     ]
    }
   ],
   "source": [
    "messages = [{'role':'user','content':\"What's the capital of Italy?\"}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt engineering \n",
    "structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\n",
      "    \"country\": \"Italy\",\n",
      "    \"capital\": \"Rome\"\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answer questions about capitals of countries.\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "[\n",
    "{\n",
    "    \"country\": the country that you will get the capital of \n",
    "    \"capital\": the capital of the country stated\n",
    "}\n",
    "]\n",
    "\"\"\"\n",
    "messages = [{\"role\":\"system\",\"content\":system_prompt}]\n",
    "messages.append({\"role\":\"user\",\"content\":\"What's the capital of Italy?\"})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input structuring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"country\": \"Italy\",\n",
      "        \"capital\": \"Rome\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"France\",\n",
      "        \"capital\": \"Paris\"\n",
      "    },\n",
      "    {\n",
      "        \"country\": \"Germany\",\n",
      "        \"capital\": \"Berlin\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Get me the capitals of the following countries:\n",
    "```\n",
    "1. Italy\n",
    "2. France\n",
    "3. Germany\n",
    "``\n",
    "\"\"\"\n",
    "messages = [{'role':'system','content':system_prompt}]\n",
    "messages.append({'role':'user','content':user_prompt})\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'country': 'Italy', 'capital': 'Rome'},\n",
       " {'country': 'France', 'capital': 'Paris'},\n",
       " {'country': 'Germany', 'capital': 'Berlin'}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = json.loads(response)\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the model time to think (Chain of thought)\n",
    "https://arxiv.org/pdf/2205.11916\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 1+3\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4113098.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "259/2*8654+91072*33-12971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"result\": 1343519\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2681649.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 1431449.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "Calculate the result of this equation: 259/2*8654+91072*33-12971\n",
    "\n",
    "Your output should be in a structured json format exactly like the one bellow. You are not allowed to write anything other than the json object:\n",
    "{\n",
    "    steps: This is where you solve the equation bit by bit following the BEDMAS order of operations. You need to show your work and calculate each step leading to final result. Feel free to write here in free text. \n",
    "    result: The final number resulted from calculating the equation above\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"steps\": \"First, calculate the division: 259/2 = 129.5. Then, multiply 129.5 by 8654: 129.5 * 8654 = 112,141.5. Next, multiply 91072 by 33: 91072 * 33 = 3,003,336. Now, add 112,141.5 and 3,003,336: 112,141.5 + 3,003,336 = 4,115,477.5. Finally, subtract 12971 from 4,115,477.5: 4,115,477.5 - 12971 = 4,005,806.5.\",\n",
      "    \"result\": 4005806.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107291.5"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4113098.0 - 4005806.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking about a subject that the LLM does not know anything about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no such thing as an \"iPhone 16\". Apple has not released an iPhone with that model number. The latest iPhone models available in the market are iPhone 13 series, which includes iPhone 13, iPhone 13 Mini, iPhone 13 Pro, and iPhone 13 Pro Max.\n",
      "\n",
      "However, if you're looking for information on the latest rumors and leaks about the next-generation iPhone, I can provide you with some information.\n",
      "\n",
      "Rumors suggest that the next-generation iPhone, likely to be called iPhone 14, will feature several upgrades and improvements, including:\n",
      "\n",
      "1. Improved cameras: The iPhone 14 is expected to feature a new triple-camera setup with a wider-angle lens, a telephoto lens, and a ultra-wide-angle lens.\n",
      "2. Faster processor: The iPhone 14 is expected to be powered by Apple's A15 Bionic chip, which will provide a significant boost in performance and efficiency.\n",
      "3. Longer battery life: The iPhone 14 is expected to have a longer battery life, with some reports suggesting up to 12 hours of internet use on a single charge.\n",
      "4. New design: The iPhone 14 is expected to feature a new design with a smaller notch, thinner bezels, and a more seamless glass front.\n",
      "5. 5G connectivity: The iPhone 14 is expected to support 5G connectivity, which will provide faster data speeds and lower latency.\n",
      "6. Improved water resistance: The iPhone 14 is expected to have improved water resistance, with some reports suggesting it will be able to withstand up to 30 feet of water.\n",
      "7. New colors: The iPhone 14 is expected to be available in new colors, including a new \"Pacific Blue\" color option.\n",
      "\n",
      "Please note that these are just rumors and leaks, and Apple has not officially confirmed any of these features. We'll have to wait for the official announcement to know the exact specifications and features of the next-generation iPhone.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving Context to the unknown subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_16 = \"\"\"\n",
    "The iPhone 16 introduces several exciting updates, making it one of Apple's most advanced smartphones to date. It features a larger 6.1-inch display for the base model and a 6.7-inch screen for the iPhone 16 Plus, with thinner bezels and a more durable Ceramic Shield. The iPhone 16 Pro and Pro Max boast even larger displays, measuring 6.3 and 6.9 inches respectively, offering the thinnest bezels seen on any Apple product so far.\n",
    "\n",
    "Powered by the new A18 chip (A18 Pro for the Pro models), these phones deliver significant performance improvements, with enhanced neural engine capabilities, faster GPU for gaming, and machine learning tasks. The camera systems are also upgraded, with the base iPhone 16 sporting a dual-camera setup with a 48MP main sensor. The Pro models offer a 48MP Ultra Wide and 5x telephoto camera, enhanced by Apple’s \"Camera Control\" button for more flexible photography options.\n",
    "\n",
    "Apple also introduced advanced audio features like \"Audio Mix,\" which uses machine learning to separate background sounds from speech, allowing for more refined audio capture during video recording. Battery life has been extended, especially in the iPhone 16 Pro Max, which is claimed to have the longest-lasting battery of any iPhone \n",
    "9TO5MAC\n",
    "\n",
    "APPLEMAGAZINE\n",
    ".\n",
    "\n",
    "Additionally, Apple has switched to USB-C for faster charging and data transfer, and the Pro models now support up to 2x faster video encoding. The starting prices remain consistent with previous generations, with the iPhone 16 starting at $799, while the Pro models start at $999\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the text, the new features and updates in the iPhone 16 include:\n",
      "\n",
      "1. Larger displays: 6.1-inch for the base model, 6.7-inch for the iPhone 16 Plus, 6.3 inches for the iPhone 16 Pro, and 6.9 inches for the iPhone 16 Pro Max.\n",
      "2. Thinner bezels and a more durable Ceramic Shield.\n",
      "3. New A18 chip (A18 Pro for the Pro models) with improved performance, neural engine capabilities, and faster GPU for gaming and machine learning tasks.\n",
      "4. Upgraded camera systems:\n",
      "\t* Base iPhone 16: dual-camera setup with a 48MP main sensor.\n",
      "\t* Pro models: 48MP Ultra Wide and 5x telephoto camera, with Apple's \"Camera Control\" button for more flexible photography options.\n",
      "5. Advanced audio features, including \"Audio Mix\" for refined audio capture during video recording.\n",
      "6. Extended battery life, especially in the iPhone 16 Pro Max, which has the longest-lasting battery of any iPhone.\n",
      "7. Switch to USB-C for faster charging and data transfer.\n",
      "8. Pro models support up to 2x faster video encoding.\n",
      "9. Starting prices remain consistent with previous generations, with the iPhone 16 starting at $799 and the Pro models starting at $999.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = f\"\"\"\n",
    "{iphone_16}\n",
    "\n",
    "What's new in iphone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role':'user','content':user_prompt}]\n",
    "response = get_chatbot_response(client,model_name,messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically extract context data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "samsung_s23 = \"\"\"\n",
    "The Samsung Galaxy S23 brings some incremental but notable upgrades to its predecessor, the Galaxy S22. It features the Snapdragon 8 Gen 2 processor, a powerful chip optimized for the S23 series, delivering enhanced performance, especially for gaming and multitasking. This chip ensures top-tier speed and efficiency across all models, from the base S23 to the larger S23+ and S23 Ultra​\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "In terms of design, the S23's camera module has been streamlined by removing the raised metal contour around the cameras, creating a cleaner, sleeker look. It also sports the same 6.1-inch 120Hz AMOLED display, protected by tougher Gorilla Glass Victus 2, making it more resistant to scratches and drops​\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "The S23 Ultra stands out with its 200MP main camera, offering impressive photo clarity, especially in low-light conditions. The selfie camera across the series has been updated to a 12MP sensor, resulting in sharper selfies. The Ultra model also includes productivity tools such as the S-Pen, which remains an essential feature for note-taking and creative tasks​\n",
    "STUFF\n",
    "\n",
    "TECHRADAR\n",
    ".\n",
    "\n",
    "Battery life is solid, with the S23 Ultra featuring a 5000mAh battery that lasts comfortably through a day of heavy use. However, charging speeds still lag behind some competitors, with 45W wired charging, which is slower than other brands offering up to 125W charging​\n",
    "STUFF\n",
    ".\n",
    "\n",
    "Overall, the Galaxy S23 series enhances performance, durability, and camera quality, making it a strong contender for users seeking a high-performance flagship.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [iphone_16,samsung_s23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"What's new in iphone 16?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_client = OpenAI(\n",
    "        api_key=os.getenv(\"RUNPOD_TOKEN\"), \n",
    "        base_url=os.getenv(\"RUNPOD_EMBEDDING_URL\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(embedding_client, model_name, text_input):\n",
    "    output = embedding_client.embeddings.create(input=text_input, model=model_name)\n",
    "    \n",
    "    embeddings = []  # Corrected the variable name\n",
    "    for embedding_object in output.data:\n",
    "        embeddings.append(embedding_object.embedding)\n",
    "\n",
    "    return embeddings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
